"""Модуль для выполнения поиска."""

import logging
import asyncio
from typing import Any, Dict, List, Optional, Tuple

from qdrant_client.http.models import FieldCondition, Filter, MatchValue, Range
from qdrant_client.models import SparseVector

from core.search.reranker_manager import RerankerManager
from config.config_manager import ConfigManager
from core.embedding.embeddings import get_dense_embedder

logger = logging.getLogger(__name__)


class SearchExecutor:
    """Класс для выполнения поисковых запросов."""
    
    @staticmethod
    async def execute_search_with_vector(
        client, 
        query: str,
        query_vector: List[float],
        k: int, 
        metadata_filter: Optional[Dict[str, Any]] = None
    ) -> Tuple[List[Tuple[Any, float]], Optional[str]]:
        """
        Выполняет поиск с использованием предварительно вычисленного вектора запроса.
        
        Args:
            client: QdrantClient.
            query (str): Оригинальный текстовый запрос (для логирования и reranking).
            query_vector (List[float]): Предварительно вычисленный вектор запроса.
            k (int): Количество результатов.
            metadata_filter (Optional[Dict[str, Any]]): Фильтр по метаданным.
            
        Returns:
            Tuple[List[Tuple[Any, float]], Optional[str]]: (результаты поиска, ошибка)
        """
        try:
            collection_name = ConfigManager.get_instance().get().collection_name  # Получаем из конфига
            # Выполняем поиск с опциональной фильтрацией по метаданным, используя готовый вектор
            if metadata_filter:
                # Создаем фильтр для Qdrant
                must_conditions = []
                
                for key, value in metadata_filter.items():
                    # Обрабатываем различные типы условий
                    if isinstance(value, dict):
                        # Сложные условия (например, {"$gt": 2020})
                        for op, op_value in value.items():
                            if op == "$gt":
                                must_conditions.append(FieldCondition(
                                    key=f"metadata.{key}",
                                    range=Range(gt=op_value)
                                ))
                            elif op == "$gte":
                                must_conditions.append(FieldCondition(
                                    key=f"metadata.{key}",
                                    range=Range(gte=op_value)
                                ))
                            elif op == "$lt":
                                must_conditions.append(FieldCondition(
                                    key=f"metadata.{key}",
                                    range=Range(lt=op_value)
                                ))
                            elif op == "$lte":
                                must_conditions.append(FieldCondition(
                                    key=f"metadata.{key}",
                                    range=Range(lte=op_value)
                                ))
                            elif op == "$contains":
                                # Для массивов или строк
                                must_conditions.append(FieldCondition(
                                    key=f"metadata.{key}",
                                    match=MatchValue(value=op_value)
                                ))
                    else:
                        # Простое равенство
                        must_conditions.append(FieldCondition(
                            key=f"metadata.{key}",
                            match=MatchValue(value=value)
                        ))
                
                search_filter = Filter(must=must_conditions)
                # Используем нативный поиск Qdrant с именованным вектором
                results = client.search(
                    collection_name=collection_name,
                    query_vector=("dense_vector", query_vector),
                    limit=k,
                    query_filter=search_filter,
                    with_payload=True,
                    with_vectors=False
                )
            else:
                # Используем нативный поиск Qdrant без фильтров с именованным вектором
                results = client.search(
                    collection_name=collection_name,
                    query_vector=("dense_vector", query_vector),
                    limit=k,
                    with_payload=True,
                    with_vectors=False
                )

            # Обрабатываем результаты для извлечения содержимого чанков
            processed_results = []
            for point in results:  # Теперь results - это список PointStruct
                # Извлекаем дополнительную информацию из payload
                payload = point.payload if hasattr(point, 'payload') else {}
                content = payload.get('content', '') or payload.get('page_content', '')
                metadata = payload.get('metadata', {})
                
                # Создаем расширенный объект результата
                extended_result = {
                    'content': content if content is not None else '',
                    'metadata': metadata,
                    'original_score': point.score if hasattr(point, 'score') else 0  # Сохраняем оригинальную оценку
                }
                
                # Если это многоуровневый чанк, добавляем информацию о микро-чанках
                if 'micro_contents' in metadata:
                    extended_result['micro_contents'] = metadata['micro_contents']
                elif 'micro_contents' in payload:
                    extended_result['micro_contents'] = payload['micro_contents']
                    
                # Добавляем source если есть
                if 'source' in metadata:
                    extended_result['source'] = metadata['source']
                elif 'source' in payload:
                    extended_result['source'] = payload['source']
                elif 'source' not in extended_result and 'source' in metadata:
                    extended_result['source'] = metadata.get('source', '')
                    
                processed_results.append((extended_result, point.score if hasattr(point, 'score') else 0))
                
            logger.debug(f"Search with vector returned {len(processed_results)} results")
            
            # Log first result before returning to see what we have
            if processed_results:
                first_result, first_score = processed_results[0]
                logger.debug(f"Before returning - First result score: {first_score}, keys: {list(first_result.keys()) if isinstance(first_result, dict) else 'not dict'}")
                if isinstance(first_result, dict):
                    logger.debug(f"Before returning - original_score: {first_result.get('original_score')}")
            
            return processed_results, None
            
        except Exception as e:
            logger.exception(f"Ошибка при поиске с вектором: {e}")
            return [], str(e)

    @staticmethod
    async def execute_hybrid_search(client, query: str, embedder, sparse_params: Dict, k: int, metadata_filter: Optional[Dict[str, Any]] = None):
        """Выполняет гибридный поиск (dense + sparse BM25)."""
        try:
            config = ConfigManager.get_instance().get()
            # Dense vector
            dense_vector = embedder.embed_query(query)
            
            # Получаем sparse vector, если доступен
            sparse_dict = None
            sparse_name = None
            if sparse_params and sparse_params.get("sparse_embedding"):
                sparse_emb = sparse_params["sparse_embedding"]
                sparse_dict = sparse_emb.embed_query(query)  # Now already in dict format from native adapter
                # sparse_dict is already in the correct format {"indices": [...], "values": [...]}

                sparse_name = sparse_params.get("sparse_vector_name", config.sparse_vector_name)
            
            collection_name = config.collection_name
            search_filter = SearchExecutor._create_filter(metadata_filter) if metadata_filter else None
            
            # Выполняем dense поиск с именованным вектором
            dense_results = client.search(
                collection_name=collection_name,
                query_vector=("dense_vector", dense_vector),
                limit=k * 2,  # Берем больше для reranking
                query_filter=search_filter,
                with_payload=True,
                with_vectors=False
            )
            
            # Выполняем sparse поиск
            sparse_results = []
            if sparse_dict and sparse_name:
                sparse_results = client.search(
                    collection_name=collection_name,
                    query_vector=None,
                    sparse_vector={sparse_name: sparse_dict},
                    vector_name=sparse_name,  # Use named sparse
                    limit=k * 2,
                    query_filter=search_filter,
                    with_payload=True,
                    with_vectors=False
                )
            
            # Комбинируем результаты (простой union с весами, alpha=0.7 для dense)
            alpha = 0.7
            # Создаем словарь для дедупликации по ID
            combined_dict = {}
            
            # Добавляем dense результаты
            for point in dense_results:
                point_id = str(point.id) if hasattr(point, 'id') else str(hash(str(point.payload)))
                score = point.score if hasattr(point, 'score') else 0
                combined_dict[point_id] = {
                    'point': point,
                    'score': alpha * score
                }
            
            # Добавляем sparse результаты
            for point in sparse_results:
                point_id = str(point.id) if hasattr(point, 'id') else str(hash(str(point.payload)))
                score = point.score if hasattr(point, 'score') else 0
                if point_id in combined_dict:
                    # Комбинируем оценки
                    combined_dict[point_id]['score'] += (1 - alpha) * score
                else:
                    combined_dict[point_id] = {
                        'point': point,
                        'score': (1 - alpha) * score
                    }
            
            # Сортируем по комбинированной оценке и берем top k
            sorted_results = sorted(combined_dict.items(), key=lambda x: x[1]['score'], reverse=True)[:k]
            
            # Обрабатываем результаты
            processed_results = []
            for point_id, data in sorted_results:
                point = data['point']
                combined_score = data['score']
                
                # Извлекаем дополнительную информацию из payload
                payload = point.payload if hasattr(point, 'payload') else {}
                content = payload.get('content', '') or payload.get('page_content', '')
                metadata = payload.get('metadata', {})
                
                # Создаем расширенный объект результата
                extended_result = {
                    'content': content if content is not None else '',
                    'metadata': metadata,
                    'original_score': combined_score
                }
                
                # Если это многоуровневый чанк, добавляем информацию о микро-чанках
                if 'micro_contents' in metadata:
                    extended_result['micro_contents'] = metadata['micro_contents']
                elif 'micro_contents' in payload:
                    extended_result['micro_contents'] = payload['micro_contents']
                    
                # Добавляем source если есть
                if 'source' in metadata:
                    extended_result['source'] = metadata['source']
                elif 'source' in payload:
                    extended_result['source'] = payload['source']
                elif 'source' not in extended_result and 'source' in metadata:
                    extended_result['source'] = metadata.get('source', '')
                
                processed_results.append((extended_result, combined_score))
            
            return processed_results, None
        except Exception as e:
            logger.exception(f"Ошибка в hybrid поиске: {e}")
            return [], str(e)

    @staticmethod
    async def execute_search(
        client, 
        search_mode: str,
        vector_name: Optional[str],
        sparse_params: Optional[Dict],
        query: str, 
        k: int, 
        metadata_filter: Optional[Dict[str, Any]] = None
    ) -> Tuple[List[Tuple[Any, float]], Optional[str]]:
        """
        Выполняет поиск с опциональной фильтрацией по метаданным.
        
        Args:
            client: QdrantClient.
            search_mode (str): Режим поиска ("dense", "sparse", "hybrid").
            vector_name (str): Имя dense vector.
            sparse_params (Dict): Параметры sparse.
            query (str): Поисковый запрос.
            k (int): Количество результатов.
            metadata_filter (Optional[Dict[str, Any]]): Фильтр по метаданным.
            
        Returns:
            Tuple[List[Tuple[Any, float]], Optional[str]]: (результаты поиска, ошибка)
        """
        try:
            config = ConfigManager.get_instance().get()
            embedder = get_dense_embedder(config, "auto")
            query_vector = embedder.embed_query(query)
            
            # Создаем фильтр, если нужно
            search_filter = SearchExecutor._create_filter(metadata_filter) if metadata_filter else None
            
            if search_mode == "hybrid":
                results, error = await SearchExecutor.execute_hybrid_search(client, query, embedder, sparse_params, k, metadata_filter)
                if error:
                    return [], error
            elif search_mode == "sparse":
                # Sparse поиск
                sparse_vector_name = sparse_params["sparse_vector_name"] if sparse_params else config.sparse_vector_name
                # Получаем sparse вектор через sparse embedding
                sparse_embedding = sparse_params.get("sparse_embedding")
                sparse_vector = None
                if sparse_embedding:
                    # sparse_result уже в формате {"indices": [...], "values": [...]} от адаптера
                    sparse_result = sparse_embedding.embed_query(query)
                    sparse_vector = sparse_result  # уже в правильном формате
                
                if sparse_vector:
                    results = client.search(
                        collection_name=config.collection_name,
                        query_vector=None,  # Для sparse поиска query_vector=None
                        sparse_vector={sparse_vector_name: sparse_vector},  # {indices: [...], values: [...]}
                        vector_name=sparse_vector_name,  # Имя sparse named vector
                        limit=k,
                        query_filter=search_filter,
                        with_payload=True,
                        with_vectors=False
                    )
                else:
                    # Если sparse вектор не создан, возвращаем пустой результат
                    results = []
            else:
                # Dense
                # Для dense векторов используем именованный вектор
                if vector_name:
                    results = client.search(
                        collection_name=config.collection_name,
                        query_vector=(vector_name, query_vector),
                        limit=k,
                        query_filter=search_filter,
                        with_payload=True,
                        with_vectors=False
                    )
                else:
                    # Если имя вектора не указано, используем имя по умолчанию "dense_vector"
                    results = client.search(
                        collection_name=config.collection_name,
                        query_vector=("dense_vector", query_vector),
                        limit=k,
                        query_filter=search_filter,
                        with_payload=True,
                        with_vectors=False
                    )
        
            # Обрабатываем результаты для извлечения содержимого чанков
            processed_results = []
            for point in results:  # Теперь results - это список PointStruct
                # Извлекаем дополнительную информацию из payload
                payload = point.payload if hasattr(point, 'payload') else {}
                content = payload.get('content', '') or payload.get('page_content', '')
                metadata = payload.get('metadata', {})
                
                # Создаем расширенный объект результата
                extended_result = {
                    'content': content if content is not None else '',
                    'metadata': metadata,
                    'original_score': point.score if hasattr(point, 'score') else 0  # Сохраняем оригинальную оценку
                }
                
                # Если это многоуровневый чанк, добавляем информацию о микро-чанках
                if 'micro_contents' in metadata:
                    extended_result['micro_contents'] = metadata['micro_contents']
                elif 'micro_contents' in payload:
                    extended_result['micro_contents'] = payload['micro_contents']
                    
                # Добавляем source если есть
                if 'source' in metadata:
                    extended_result['source'] = metadata['source']
                elif 'source' in payload:
                    extended_result['source'] = payload['source']
                elif 'source' not in extended_result and 'source' in metadata:
                    extended_result['source'] = metadata.get('source', '')
                    
                processed_results.append((extended_result, point.score if hasattr(point, 'score') else 0))
                
            logger.debug(f"Search returned {len(processed_results)} results")  # Оставить
            
            # Log first result before returning to see what we have
            if processed_results:
                first_result, first_score = processed_results[0]
                logger.debug(f"Before returning - First result score: {first_score}, keys: {list(first_result.keys()) if isinstance(first_result, dict) else 'not dict'}")
                if isinstance(first_result, dict):
                    logger.debug(f"Before returning - original_score: {first_result.get('original_score')}")
        
            return processed_results, None
            
        except Exception as e:
            logger.exception(f"Ошибка при поиске: {e}")
            return [], str(e)

    @staticmethod
    def _create_filter(metadata_filter: Optional[Dict[str, Any]]) -> Optional[Filter]:
        """Вспомогательный метод для создания фильтра."""
        if not metadata_filter:
            return None
        must_conditions = []
        for key, value in metadata_filter.items():
            # Обрабатываем различные типы условий
            if isinstance(value, dict):
                # Сложные условия (например, {"$gt": 2020})
                for op, op_value in value.items():
                    if op == "$gt":
                        must_conditions.append(FieldCondition(
                            key=f"metadata.{key}",
                            range=Range(gt=op_value)
                        ))
                    elif op == "$gte":
                        must_conditions.append(FieldCondition(
                            key=f"metadata.{key}",
                            range=Range(gte=op_value)
                        ))
                    elif op == "$lt":
                        must_conditions.append(FieldCondition(
                            key=f"metadata.{key}",
                            range=Range(lt=op_value)
                        ))
                    elif op == "$lte":
                        must_conditions.append(FieldCondition(
                            key=f"metadata.{key}",
                            range=Range(lte=op_value)
                        ))
                    elif op == "$contains":
                        # Для массивов или строк
                        must_conditions.append(FieldCondition(
                            key=f"metadata.{key}",
                            match=MatchValue(value=op_value)
                        ))
            else:
                # Простое равенство
                must_conditions.append(FieldCondition(
                    key=f"metadata.{key}",
                    match=MatchValue(value=value)
                ))
        return Filter(must=must_conditions)